**Приложение:** https://ai-hw1-pro-avanesyan.streamlit.app/

# Что было сделано

## Часть 1 | EDA

Вначале я загрузила исходный датасет, изучила его структуру и представленные в его ячейках типы данных. Также провела подсчет пропусков и дубликатов.
Для строковых колонок выполнила очистку и нормализацию форматов. Пропуски в числовых колонках заполнила медианой.

Далее был проведён полный EDA на обучающем датасете:
- изучены размеры выборки, типы данных и базовые статистики;
- проверено распределение признаков;
- проанализированы пропуски и заменены;
- построены гистограммы, boxplot, heatmap, категориальные распределения.

Иным словами, я изучила и подготовила данные для последующего обучения модели. Что касается кодирования данных для ml-модели, я преобразовала категориальные признаки в числовые с помощью One-Hot Encoding (OHE), также при формировании итогового датасета исключала некоторые столбцы, которые либо совсем не влияли на значение целевой переменной или были в сильной кореляции с другими признами.

## Часть 2 | Модель только на вещественных признаках

На этом этапе были построены базовые модели линейной регрессии, Lasso и ElasticNet, используя только числовые признаки.
Для подбора гиперпараметров я использовала GridSearchCV. Качество моделей преимущественно оценивала на обучающем и тестовом наборах с помощью метрики R².

Также я проверила значимость признаков по весам модели, а также влияние регуляризации на уменьшение переобучения.

Выявлено, что модели без регуляризации склонны к переобучению, особенно на тестовой выборке.

Также стоит отметить, что модели на вещественных признаках дают среднее качество предсказаний, однако без обработки категориальных данных и без регуляризации точность на тестовой выборке ограничена (максимальное значение метрики R² достигало 0.59 на тестовых данных).

## Часть 3 | Добавляем категориальные фичи

Для повышения качества прогнозов:
- Были добавлены категориальные признаки с помощью One-Hot Encoding (OHE), при этом один столбец каждого признака удалялся для избежания мультиколлинеарности.
- Использована Ridge-регрессия с подбором параметра регуляризации alpha через GridSearchCV с 10-фолдовой кросс-валидацией.
- Проведена оценка модели на тестовой выборке и по бизнес-метрике (доля предсказаний ±10% от реальной цены).

Результаты:
| Модель       | R² train | R² test | Бизнес-метрика ±10% |
| ------------ | -------- | ------- | ------------------- |
| Ridge (best) | 0.95     | 0.94    | 0.45                |

## Часть 4. | Бизнесовая

Для оценки моделей с точки зрения бизнеса я реализовала две кастомные метрики.
- Метрика ±10% от реальной цены:
Сначала я посчитала долю предсказаний, которые отличаются от реальной цены не более чем на 10%. Такая метрика показывает, насколько часто модель «попадает» в разумный диапазон, что важно для принятия решений по продаже автомобилей. По этой метрике Ridge-модель показала лучший результат — около 40–45% точных прогнозов, тогда как LinearRegression, Lasso и ElasticNet были значительно хуже (~21%), что говорит о том, что только Ridge достаточно надёжно предсказывает цены в бизнес-контексте.

- Асимметричная бизнес-метрика:
Так как недооценка цены для бизнеса хуже перепрогноза, я добавила метрику, где недопрогнозы более чем на 10% штрафуются, а перепрогнозы до 10% допускаются. По этой метрике Ridge показала ещё более высокие результаты (0.757 на трейне, 0.724 на тесте), что подтвердило её преимущество. Остальные модели снова показали значительно более низкую способность избегать недооценки (~0.644 на тесте).

## Часть 5 | Создание интерактивного приложения на Streamlit

Для наглядного использования модели и демонстрации работы системы был разработан интерактивный веб-сервис на Streamlit.

Сервис доступен для локального запуска через команду:

```streamlit run app.py``` (предварительно нужно скачать зависимости из requirements.txt)

А также по ссылке https://ai-hw1-pro-avanesyan.streamlit.app/.


# Какие результаты были получены (метрики и интерпретация)

Метрики:
- R² оценивает, насколько хорошо модель объясняет вариацию цены в данных.
- Бизнес-метрика ±10% показывает практическую точность предсказаний для реальных задач
- Асимметричная бизнес-метрика отражает предпочтения бизнеса (не недооценивать цену)
- 
- Модели на вещественных признаках (LinearRegression, Lasso, ElasticNet) показали среднее качество: R² на тесте около 0.59, бизнес-метрика ±10% — примерно 0.21. Это говорит о том, что модели плохо справляются с точным прогнозированием цен без учета категориальных признаков и регуляризации.
- Ridge-регрессия с учетом категориальных признаков (OHE) показала наибольшую точность: R² на тесте 0.94, бизнес-метрика ±10% — 0.45. То есть модель достаточно хорошо предсказывает цены, попадая в разумный диапазон почти в половине случаев.
- Асимметричная бизнес-метрика показала ещё более высокую эффективность Ridge-модели: 0.724 на тесте (те модель умеет избегать недопрогноза). Остальные модели показывают значительно более низкий результат (~0.644).

# Что дало наибольший прирост качества

Наибольший прирост качества дала комбинация добавления категориальных признаков через One-Hot Encoding и использование регуляризации в Ridge-регрессии, что позволило увеличить R² с ~0.59 до 0.94 и улучшить бизнес-метрику ±10% почти вдвое.

# Оценка разработанного сервиса

- *Удобство в использовании*
Приложение на Streamlit интуитивно понятно: можно загружать данные, настраивать признаки и получать предсказания модели.

- *Что получилось визуализировать хорошо*
На мой взгляд, самой наглядной визуализацией является тепловая кореляционная карта (тк там нет нечитаемых подписей + она яркая, её приятно изучать).
Также информативны гистограммы распределений признаков, boxplot. Важным является блок "пропущенные значения", что помогает человеку учитывать полноту его датасета.

- *Что получилось менее удачно*
Самое большое препятствие - длинные в категориальных данных (например, я добавила визуализацию в виде гистограммы категориальных значений, и из-за большой длины поля name мы получаем нечитаемые названия осей). Если говорить про числовые колонки, то, тк гистограммы отражают распределение, такие графики можно прочитать, но если числовых значений того или иного признака действительно много, то воспринимать информацию уже сложнее.

- *Какие улучшения планируете в следующей итерации*
Я бы встроила в свой код более провдинутые средства визуализации (даже в том же самом Plotly), тк нам необходима функция zoom in/zoom out, движение по графику и т.д. (то есть некая динамичность, которую может предложить, напмимер, plotly).
